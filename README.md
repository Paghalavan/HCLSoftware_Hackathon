Hereâ€™s a **clean, professional README** you can drop directly into your backend repo.
Itâ€™s written to sound **industry-grade**, **hackathon-appropriate**, and **judge-friendly**.

---

# Customer Value Prediction Backend

This repository contains the **backend service** for predicting **customer future spend** and **purchase likelihood** using transaction-derived features.
The service exposes a REST API built with **FastAPI**, integrates a **trained machine learning model**, and augments predictions with **LLM-based business insights**.

---

## ğŸš€ Features

* Predicts **future spend over the next 30 days**
* Estimates **probability of purchase in the next 30 days**
* Uses a **trained ML regression model** (`model.pkl`)
* Applies a **heuristic-based intent signal** (recency + frequency)
* Generates **business-friendly insights and recommended actions** using an LLM
* Production-ready FastAPI architecture
* Deployed on **Render**

---

## ğŸ§  Model Overview

The trained model was built using the following customer-level features:

| Feature       | Description                   |
| ------------- | ----------------------------- |
| Recency       | Days since last purchase      |
| Frequency     | Number of transactions        |
| Total Spend   | Cumulative spend              |
| Average Spend | Average spend per transaction |

At inference time, the API **explicitly selects and orders these features** to match the modelâ€™s training configuration, ensuring correctness and forward compatibility.

---

## ğŸ—ï¸ Architecture

1. Client (Frontend / Postman) sends customer features
2. FastAPI backend:

   * Maps input features to model-expected format
   * Runs ML prediction
   * Computes purchase probability (heuristic)
3. Prediction + probability are passed to an LLM
4. LLM returns:

   * Customer segment
   * Business insight
   * Recommended action
5. Structured JSON response returned to client

---

## ğŸ“¦ Tech Stack

* **FastAPI** â€“ API framework
* **scikit-learn** â€“ ML model inference
* **NumPy** â€“ numerical processing
* **Groq LLM API** â€“ insight generation
* **Uvicorn** â€“ ASGI server
* **Render** â€“ cloud deployment

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app.py                # FastAPI application
â”œâ”€â”€ model/
â”‚   â””â”€â”€ model.pkl         # Trained ML model
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ README.md
```

---

## âš™ï¸ Environment Variables

Create a `.env` file with:

```env
GROQ_API_KEY=your_groq_api_key
```

---

## â–¶ï¸ Running Locally

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Start the server

```bash
uvicorn app:app --reload
```

### 3. Open API docs

```
http://127.0.0.1:8000/docs
```

---

## ğŸŒ Production Deployment (Render)

**Start Command**

```bash
uvicorn app:app --host 0.0.0.0 --port $PORT
```

The backend listens on the port provided by Render and is publicly accessible.

---

## ğŸ”— API Endpoint

### `POST /predict_customer_value`

#### Request Body

```json
{
  "customer_id": "13085",
  "features": [345.7, 49.3, 7, 12, 5, 4]
}
```

#### Feature Order

```
[
  total_spend,
  avg_spend,
  num_transactions,
  total_units,
  unique_products,
  recency_days
]
```

---

#### Response

```json
{
  "customer_id": "13085",
  "predicted_future_spend_30d": 512.4,
  "purchase_probability_30d": 0.83,
  "customer_segment": "High Value",
  "insight": "Customer shows strong recent engagement and high spending potential.",
  "recommended_action": "Offer personalized promotions or loyalty rewards."
}
```

---

## ğŸ“Š Purchase Probability Logic

Purchase probability is computed using a deterministic heuristic:

* **Recency decay** â€“ recent customers are more likely to return
* **Frequency boost** â€“ frequent buyers have higher intent

This signal complements spend prediction by capturing **customer intent**, not just value.

---

## ğŸ§ª Testing

* API tested via **Postman**
* Multiple customer archetypes validated:

  * High-value active
  * At-risk churn
  * New customer
  * Habitual buyer
  * Low-value inactive

---

## ğŸ§© Design Decisions

* **Model-agnostic API** â€“ inference layer adapts to model features
* **Explicit feature mapping** â€“ avoids silent mismatches
* **Forward-compatible schema** â€“ allows future feature expansion
* **Business guardrails** â€“ prevents unrealistic outputs

---

## ğŸ Summary

This backend demonstrates:

* End-to-end ML inference
* Production-ready API design
* Clear separation of concerns
* Business-aligned outputs
* Cloud deployment best practices

Absolutely â€” hereâ€™s the **updated README section** with a clean, professional **Contributors** block added.
You can paste this directly into your backend README.

---

## ğŸ‘¥ Contributors

This project was developed collaboratively with clearly defined responsibilities:

* **Lakshya Tiwari**
  *Backend Development, Deployment & System Integration*

  * Designed and implemented the FastAPI backend
  * Integrated ML inference and LLM-based insights
  * Handled cloud deployment and end-to-end integration

* **Raghav**
  *Prediction Models (Random Forest & Lasso Regression)*

  * Feature engineering for customer-level modeling
  * Trained and validated regression models
  * Exported trained models for backend inference

* **Paghallavan**
  *Frontend Development & Presentation*

  * Built the TypeScript-based frontend
  * Integrated backend APIs into UI workflows
  * Designed presentation and demo narrative
---
